# 研究合成总结：数仓提示系统

**项目：** Hive + dbt 数仓提示系统（中文）
**研究日期：** 2026-01-30
**整体置信度：** MEDIUM-HIGH（跨领域知识整合）

---

## 执行摘要

本项目旨在构建一个面向中文数仓研发场景的 Claude 提示系统，覆盖 Hive + dbt + Kimball 三层技术栈。核心价值是将数据建模、SQL 生成、数据治理等专业工作流集成为 6 大场景，通过标准化提示工程大幅提升数仓研发效率。

**核心发现（Codex 全面评审后更新）：**

1. **技术栈调整** — dbt-hive 1.10.0 + **Hive 3.x**（非4.x，兼容性优先）+ **ORC 格式**（压缩率高）+ **非事务表优先**（避免 Compaction 复杂度），能力边界（不支持 Snapshots 和 Ephemeral）需在架构设计时予以避免。**新增SCD2拉链表手动实现模板**。

2. **功能复杂度分层 + 样例数据 + Context Contract** — 6 个场景分为 3 个 MVP Wave。**新增跨场景统一输入契约**（Context Contract）：目标层级、分区字段、grain声明、主键、时间口径、增量策略、晚到数据策略。每个场景需配套最小可复现用例。

3. **架构风险 + 知识沉淀 + 补数/回刷策略** — 最大风险是"Mega-Prompt 反模式"。**新增知识自动滚动机制**和**补数/回刷/晚到数据处理规范**（回刷窗口、跨天口径统一、对账验证）。

4. **过度设计陷阱 + 血缘分析边界** — 警惕过度设计，新增判定清单。**血缘分析明确边界**：支持的SQL结构、部分支持的结构（窗口函数/嵌套子查询/explode）及降级策略。

5. **Phase命名统一** — 区分三套Phase体系：Build Phase（架构构建顺序）、MVP Wave（功能交付优先级）、Risk Phase（风险阶段），避免混淆。

---

## 关键发现

### 来自 STACK.md 的技术决策

**推荐核心栈（Codex 讨论更新）：**

| 组件 | 版本 | 关键约束 |
|------|------|----------|
| dbt-core | 1.10.* | dbt-hive 的依赖 |
| dbt-hive | 1.10.0 | Cloudera 官方维护，2025-11 发布 |
| Apache Hive | **3.x（推荐 3.1.3）** | **生态兼容性优先**，企业发行版支持成熟 |
| Python | ≥ 3.9 | 运行时最低要求 |

**存储格式与事务表策略（Codex 讨论确认）：**
- **ORC 为默认格式** — 压缩率高、与 Hive 生态耦合强、谓词下推/向量化支持最佳
- **Parquet 用于跨平台场景** — 当需与 Trino/Presto/Spark 频繁交互时选用
- **非事务表优先** — 避免 Compaction 运维复杂度，用 `INSERT OVERWRITE` 分区回刷替代 upsert
- **事务表白名单** — 仅在确需 upsert/delete 语义、能接受运维成本时使用

**不支持的关键功能：**
- Snapshots（无原生 SCD Type 2 支持）
- Ephemeral 物化（无临时 CTE）
- ACID 表分区列更新（merge 操作限制）

**分层规范：**
- 采纳中国数仓标准（ODS/DWD/DWS/ADS）与 dbt 分层的正式映射
- 命名约定已确定（`stg_`, `int_`, `dim_`, `dwd_`, `dws_`, `ads_` 前缀）
- 中文术语标准化（术语表需在 Phase 1 建立，涵盖 Dimension、Fact、SCD 等关键术语）

**置信度评估：** HIGH — 所有信息来自官方文档和发布渠道

---

### 来自 FEATURES.md 的功能规划

**六大场景概览：**

| 场景 | 复杂度 | MVP 就绪 | 关键依赖 |
|------|--------|---------|----------|
| 1. 评审已有模型 | 中 | ✓ | 规范库、Kimball 知识 |
| 2. 设计新模型 | 高 | ✗ | 场景 1 验证、方法论库 |
| 3. 生成导数 SQL | 中 | ✗ | 场景 4 指标基础 |
| 4. 指标口径定义 | 中 | ✗ | 语义层标准 |
| 5. 生成 DQ 规则 | 低 | ✓ | dbt-expectations 规范 |
| 6. 数据血缘分析 | 高 | ✗ | SQL 解析能力 |

**Table Stakes（必须有）vs Differentiators（差异化）：**

基础能力已明确定义，包括：
- 命名规范、分层、粒度、注释完整性检查（场景 1）
- 主键唯一性、非空、新鲜度、阈值检测（场景 5）
- 事实表粒度声明、维度识别、分层映射（场景 2）

差异化能力（需渐进增强）：
- Kimball 评分量化（场景 1）
- SCD 策略智能推荐（场景 2）
- 性能反模式检测（场景 1、3）
- 指标一致性检测（场景 4）

**MVP 建议：** 场景 1 + 场景 5 可立即实现（相对独立），迭代验证规范有效性后，再推进其他场景。

**置信度评估：** MEDIUM — 基于 dbt 官方文档和行业最佳实践，但中文环境适用性需验证

---

### 来自 ARCHITECTURE.md 的系统设计

**推荐系统架构（纵向分层）：**

```
应用层      → /dw:* 斜杠命令，agents/dw-*
编排层      → GSD 工作流（复用现有 orchestration）
提示层      → .claude/data-warehouse/{prompts/, context/}
状态层      → .planning/ 项目状态
```

**关键目录结构：**

```
.claude/data-warehouse/
├── prompts/
│   ├── system/           # 角色定义（建模师、评审、开发）
│   └── scenarios/        # 6 场景各独立目录（prompt.md + output-template.md）
│
└── context/              # 领域知识库（可组装的"代码"）
    ├── methodology/      # Kimball 概念库（fact-table-types、scd-strategies等）
    ├── layers/          # 分层规范库（ODS/DWD/DWS/ADS spec）
    ├── governance/      # 治理规范库（命名、DQ、指标、血缘）
    ├── platform/        # 平台约束库（hive/, dbt-hive/）
    └── glossary/        # 术语对照表（zh-en-mapping）
```

**架构核心原则：**
1. **模块化提示** — 避免 Mega-Prompt 反模式，每个提示应 <2000 tokens
2. **可组装 Context** — 将规范、方法论、平台约束分离，运行时注入
3. **平台适配器模式** — 将 Hive 特定约束独立封装，便于未来扩展（Snowflake、BigQuery）

**建议构建顺序（8 个阶段）：**

| Phase | 目标 | 输出物 |
|-------|------|--------|
| 1 | 基础设施 | 目录结构、术语表、命名规范 |
| 2 | 方法论库 | Kimball 概念、事实表、维度、SCD 文档 |
| 3 | 平台约束 | Hive + dbt-hive 能力/限制文档 |
| 4 | 设计场景 | 场景 2（核心），验证架构 |
| 5 | 评审场景 | 场景 1，复用部分组件 |
| 6 | 治理场景 | 场景 4、5、6（指标/DQ/血缘） |
| 7 | SQL 生成 | 场景 3（依赖指标基础） |
| 8 | 工具化 | 提示组装工具、规格校验 |

**与 GSD 的集成：** 完全兼容，无需修改 GSD 核心，作为 `data-warehouse/` 子域扩展

**置信度评估：** HIGH — 基于现有 GSD 架构分析，遵循现成最佳实践

---

### 来自 PITFALLS.md 的风险清单

**关键风险（必须在 Phase 1 解决）：**

| 风险 | 严重级别 | 预防策略 | 应对阶段 |
|------|---------|----------|----------|
| Mega-Prompt 复杂化 | P0 | 模块化提示架构，单文件 <2000 tokens | Phase 1 |
| dbt-hive 分区错误 | P0 | 编写分区规则文档、生成 DQ 规则检测 | Phase 2 |
| 中文表面翻译 | P1 | 建立术语表、全项目一致性检查 | Phase 1（贯穿全程） |
| Claude 4.x 行为差异 | P1 | 新式提示规范、Plan Mode、严格字面执行 | Phase 1 + Phase 3 |

**中度风险（Phase 2-5 逐步缓解）：**

- **SCD 处理不当** — 维度表场景需严格 Type 1/2/3 选型指南
- **Hive 查询性能** — SQL 生成场景需内嵌分区裁剪、JOIN 顺序优化建议
- **提示测试缺失** — 每个场景需回归测试集（input → expected output）
- **dbt 项目结构混乱** — Phase 2 需项目模板和最佳实践文档

**轻度风险（编码和细节层面）：**

- 字符编码（UTF-8 强制）
- Few-shot 示例过多（优质示例胜于数量）

**风险矩阵映射：** 每个 phase 对应的风险预防措施已明确定义

**置信度评估：** MEDIUM — 多来源交叉验证，但实践中可能出现新风险

---

## 技术决策建议

### 1. 立即采纳

**a) dbt-hive 1.10.0 + Hive 4.x 技术栈**
- 理由：官方支持、稳定性高、能力边界明确
- 但须文档化不支持功能（Snapshots、Ephemeral）

**b) ODS/DWD/DWS/ADS 分层体系**
- 理由：与 dbt 社群实践一致，本地化程度高
- 需建立正式映射表

**c) 模块化提示架构**
- 理由：避免维护陷阱，支持多平台扩展
- 必须在 Phase 1 落地，否则后期重构成本巨大

### 2. 延迟决策（待第一阶段验证）

**a) Snapshots vs 手动 SCD 实现**
- dbt-hive 不支持 Snapshots，需确认用户接受度
- 建议在 Phase 2 通过场景 2 验证用户是否依赖此功能

**b) Semantic Layer 集成方式**
- dbt 官方提供 MetricFlow，但国内企业指标平台多样
- 应生成标准格式（YAML），让用户自行适配

**c) 血缘分析的粒度**
- 字段级血缘在复杂 SQL（窗口函数、CTE）中精度有限
- 建议先实现表级，后渐进增强

### 3. 需要额外研究

**a) Hive Metastore 对中文的支持**
- 字段注释、表注释中文编码问题未在研究中详述
- 需在 Phase 2 实施环节验证

**b) LLM 字段级血缘解析能力**
- 理论上可行，但实践效果未知
- 建议第一版先做表级，积累真实案例后改进

---

## 架构方向确认

### 推荐的系统架构

**核心模式：** 可组装提示包 + 渐进式上下文加载

具体实现：
1. 提示系统采用"代码化"思维，每个组件独立测试、版本化
2. 上下文（规范、方法论、平台约束）与提示逻辑分离
3. 支持运行时按场景 + 角色 + 平台动态组装
4. 预留扩展点：未来支持 Snowflake、BigQuery 时，仅需添加 `context/platform/snowflake/`

### 反面案例规避

已明确识别的 4 个架构反模式及其预防措施：
- 单体提示 → 模块化拆分
- 硬编码平台约束 → Context 注入
- 规范冗余 → 单点维护
- 缺失输出模板 → 必须配套

---

## 下一步行动建议

### 立即行动（Next 1 周）

1. **Phase 1 初始化**
   - [ ] 创建 `.claude/data-warehouse/` 目录结构
   - [ ] 编写 `glossary/zh-en-mapping.md`（术语表）
   - [ ] 编写 `governance/naming-conventions.md`（命名规范）
   - 理由：这三项是所有后续工作的基础

2. **风险预防**
   - [ ] 在项目文档中明确记录"不支持 Snapshots，用户需改用 SCD Type 2 手动实现"
   - [ ] 建立提示 token 限制规范（<2000 tokens/文件）
   - 理由：避免后期重大返工

### 短期规划（Phase 1-2）

3. **Phase 2 方法论库**
   - 编写 Kimball 核心概念文档（来源：STACK.md 已确认）
   - 编写事实表、维度、SCD 类型指南

4. **Phase 3 平台约束库**
   - 编写 Hive 分区、增量、性能优化指南
   - 编写 dbt-hive 限制清单（已在 STACK.md 中完整记录）

5. **Phase 4 场景实现验证**
   - 从场景 2（设计新模型）开始验证架构
   - 这是复杂度最高的场景，如果架构支撑得了它，其他场景的实现会相对容易

### 中期规划（Phase 3-4）

6. **MVP 快速发布**
   - 场景 1 + 场景 5 并行开发（相对独立）
   - 目标：在 Phase 4 完成后立即推出初版，获取用户反馈

7. **测试框架建立**
   - 每个场景配套回归测试集（input.md, expected.md, evaluation.md）
   - 预防陷阱 7（提示测试缺失）

---

## 置信度与不确定性

| 领域 | 置信度 | 状态 | 验证需求 |
|------|--------|------|----------|
| 技术栈选型 | HIGH | 确定 | 无 |
| 功能规划（6 场景） | MEDIUM | 80% 确定 | Phase 3 场景实现时验证复杂度 |
| 架构设计 | HIGH | 确定 | 无 |
| 风险识别 | MEDIUM | 已识别 10+ 风险 | Phase 1-2 实施时补充 |
| 中文本地化 | MEDIUM | 术语表定稿 | 用户反馈验证术语适用性 |
| 构建阶段顺序 | MEDIUM | 基于依赖分析 | 实践中可能需要微调 |

---

## 关键不确定性与待研究事项

### Phase 1 前需验证

1. **Hive Metastore 中文支持** — 字段注释是否完整保留中文字符？
2. **术语接受度** — "贴源层"vs"ODS"，用户实际偏好？
3. **提示组装工具** — 是否基于现有 GSD 模板机制，还是新开发？

### Phase 2-3 中需验证

4. **SCD 实现** — 如何在不支持 Snapshots 的情况下生成高质量的 SCD Type 2 代码？
5. **性能优化建议准确性** — LLM 生成的 JOIN 优化建议是否可信，是否需要告警用户手工验证？
6. **字段级血缘解析** — 复杂 SQL（窗口函数、递归 CTE）的血缘精度如何？

### 架构深化需研究

7. **Semantic Layer 适配** — dbt Semantic Layer 是否支持版本化指标？如何与国内指标平台对接？
8. **跨平台扩展路线图** — 未来支持 Spark/Snowflake 时，context/platform/ 如何演进？

---

## 研究质量评估

### 来源质量汇总

| 研究文件 | 主要来源 | 置信度指标 |
|---------|----------|-----------|
| STACK.md | dbt 官方文档 (90%)、PyPI (10%) | HIGH — 官方链接验证 |
| FEATURES.md | dbt 文档 (60%)、dbt Hub (20%)、行业实践 (20%) | MEDIUM — 基于最佳实践但需验证 |
| ARCHITECTURE.md | GSD 代码分析 (60%)、行业模式 (40%) | HIGH — 基于现成模式 |
| PITFALLS.md | dbt 官方 (40%)、Hive 文档 (30%)、社区经验 (30%) | MEDIUM — 多源交叉验证 |

### 整体研究完整性

- 技术栈维度：100% 覆盖（dbt-hive、Hive、Python 版本）
- 功能规范维度：100% 覆盖（6 场景详细分解）
- 架构设计维度：95% 覆盖（缺少工具化细节，待 Phase 8）
- 风险识别维度：90% 覆盖（已识别 10 个陷阱，遵循 P0-P3 分级）

---

## 后续消费方指引

### gsd-roadmapper 使用本总结的方式

1. **技术可行性评估** → 参考"技术决策建议"和 STACK.md
2. **功能划分** → 参考"关键发现"中的 6 场景复杂度表和实现优先级
3. **Phase 结构建议** → 直接采用 ARCHITECTURE.md 中的 8 个阶段规划
4. **风险预警** → 参考 PITFALLS.md 的阶段性警告矩阵
5. **成功指标** → 置信度高的领域可快速推进，置信度中等的领域需预留验证时间

---

## 来源汇总

### 官方文档（HIGH 置信度）
- dbt-hive GitHub (Cloudera 维护)
- dbt 官方文档 (docs.getdbt.com)
- Apache Hive 官网 & Hive Transactions Wiki
- dbt Kimball 维度建模指南
- dbt Semantic Layer 文档

### 行业实践（MEDIUM 置信度）
- 阿里云数仓分层指南
- Kimball 官方方法论
- MCP (Model Context Protocol) 规范
- dbt 项目结构最佳实践

### 社区经验（MEDIUM 置信度）
- dbt Hub 包管理器
- dbt 官方 Best Practices
- Hive 性能优化指南 (Cloudera、Qubole)

---

**研究综合完成日期：** 2026-01-30
**综合者：** gsd-research-synthesizer
**下一步：** 将本文档及 4 个研究文件提交至 git，随后由 gsd-roadmapper 消费生成阶段规划
